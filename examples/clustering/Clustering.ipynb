{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Metrics:\n",
    "\n",
    "**Author:** Matt Q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: c:\\Users\\miqui\\OneDrive\\Python-Projects\\Thieu Metrics Collaboration\\permetrics\\examples\\clustering\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Working dir:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "iris = pd.read_csv(\"C:/Users/miqui/OneDrive/ML-DL-Datasets/IrisData.csv\")\n",
    "dfSample = pd.read_csv(\"C:/Users/miqui/OneDrive/CSU Classes/Exit Project/Clustering Project/SampleData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the Iris dataset:\n",
    "my_dict = {\"Iris-setosa\": 0,\n",
    "           \"Iris-versicolor\": 1,\n",
    "           \"Iris-virginica\": 2}\n",
    "iris[\"Labels\"] = iris[\"Species\"].map(my_dict)\n",
    "X_iris = iris.iloc[:, 0:4]\n",
    "labels = iris.iloc[:, 5]\n",
    "\n",
    "del my_dict\n",
    "\n",
    "# Shifting the labels to be 0, 1, 2 instead of 1, 2, 3:\n",
    "labels2 = np.array(labels) - 1\n",
    "np.unique(labels2)\n",
    "\n",
    "\n",
    "X_sample = dfSample[[\"V1\", \"V2\", \"V3\"]]\n",
    "X_array = np.array(X_sample)\n",
    "y_sample = dfSample[[\"Labels\"]]\n",
    "y_labels = y_sample - 1\n",
    "y_array = np.array(y_labels).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Centroids per Cluster:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(X: pd.DataFrame, labels):\n",
    "    \"\"\"\n",
    "    Calculates the centroids from the data given labels\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame, np.ndarray): The original data that was clustered\n",
    "        labels (list. pd.DataFrame, np.ndarray): The predicted cluster assignment values\n",
    "\n",
    "    Returns:\n",
    "        centroids (np.ndarray): The centroids given the input data and labels\n",
    "    \"\"\"\n",
    "    x = pd.DataFrame(X)\n",
    "    labels = np.array(labels)\n",
    "    k = int(np.max(labels) + 1)\n",
    "    n_cols = x.shape[1]\n",
    "    centers = np.array(np.zeros(shape=(k, n_cols)))\n",
    "\n",
    "    # Getting the centroids:\n",
    "    for i in range(k):\n",
    "        centers[i, :] = np.mean(x.iloc[labels == i], axis=0)\n",
    "\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9. ,  2. , 18. ],\n",
       "       [ 6. ,  5. , 15. ],\n",
       "       [ 2.5,  8.5, 11.5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_centroids(X_sample, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids_new(X, labels):\n",
    "    \"\"\"\n",
    "    Calculates the centroids from the data given, for each label\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame, np.ndarray): The original data that was clustered\n",
    "        labels (list, np.ndarray): The predicted cluster assignment values\n",
    "\n",
    "    Returns:\n",
    "        centroids (np.ndarray): The centroids given the input data and labels\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    n_classes = len(np.unique(labels))\n",
    "    # Mask mapping each class to its members.\n",
    "    centroids = np.empty((n_classes, n_features), dtype=np.float64)\n",
    "    # Number of clusters in each class.\n",
    "    nk = np.zeros(n_classes)\n",
    "\n",
    "    for cur_class in range(n_classes):\n",
    "        centroid_mask = labels == cur_class\n",
    "        nk[cur_class] = np.sum(centroid_mask)\n",
    "        centroids[cur_class] = X[centroid_mask].mean(axis=0)\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9. ,  2. , 18. ],\n",
       "       [ 6. ,  5. , 15. ],\n",
       "       [ 2.5,  8.5, 11.5]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_centroids_new(X_array, y_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('MLDL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f294934ec600687241badbba13b5ef9e354863a1e6583340aa87f207e4656842"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
