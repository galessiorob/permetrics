A10 - A10 index
===============

.. toctree::
   :maxdepth: 3
   :caption: A10 - A10 index

.. toctree::
   :maxdepth: 3

.. toctree::
   :maxdepth: 3

.. toctree::
   :maxdepth: 3


.. math::

	\text{A10}(y, \hat{y}) = \frac{1}{n}\sum_{i=1}^{n} \left\{\begin{array}{ll} 1, & \textrm{if } \frac{|\hat{y}_i - y_i|}{y_i} \leq 0.1\\ 0, & \textrm{otherwise} \end{array}\right.

Latex equation code::

	\text{A10}(y, \hat{y}) = \frac{1}{n}\sum_{i=1}^{n} \left\{\begin{array}{ll} 1, & \textrm{if } \frac{|\hat{y}_i - y_i|}{y_i} \leq 0.1\\ 0, & \textrm{otherwise} \end{array}\right.


+ Best possible score is 1.0, bigger value is better. Range = [0, 1]
+ a10-index is engineering index for evaluating artificial intelligence models by showing the number of samples that fit the
prediction values with a deviation of Â±10% compared to experimental values
+ `Link to equation <https://www.mdpi.com/2076-3417/9/18/3715/htm>`_

In other words, the A10 metric measures the proportion of cases where the absolute difference between the predicted and actual values is less than or equal
to 10% of the actual value. A higher A10 score indicates better predictive accuracy, as the model is able to make more accurate predictions that are closer
to the actual values.


Example to use A10 metric:

.. code-block:: python
	:emphasize-lines: 8-9,15-16

	from numpy import array
	from permetrics.regression import RegressionMetric

	## For 1-D array
	y_true = array([3, -0.5, 2, 7])
	y_pred = array([2.5, 0.0, 2, 8])

	evaluator = RegressionMetric(y_true, y_pred)
	print(evaluator.a10_index())

	## For > 1-D array
	y_true = array([[0.5, 1], [-1, 1], [7, -6]])
	y_pred = array([[0, 2], [-1, 2], [8, -5]])

	evaluator = RegressionMetric(y_true, y_pred)
	print(evaluator.A10(multi_output="raw_values"))
